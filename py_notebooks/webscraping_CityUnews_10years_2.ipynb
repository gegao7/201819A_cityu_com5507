{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Web scraping\n",
    "## Workout 3. Scraping multiple pages \n",
    "\n",
    "- CityU COM5507 201819A - Unit 2: Web data collection\n",
    "- 3 Oct 2018, Week 5: web scraping ep 1\n",
    "\n",
    "\n",
    "- Course Instructor: [Dr. Xinzhi Zhang](www.drxinzhizhang.com)  (JOUR, Hong Kong Baptist University) \n",
    "  - xzzhang2@gmail.com\n",
    "\n",
    "\n",
    "- The codes in this notebook are modified from various sources. All codes are for educational purposes only and released under the CC1.0. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## once upon a time in CityU, once again - a decade: 2008 - 2018 \n",
    "\n",
    "- this file contains the debugging \n",
    "- as well as two challenges! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests \n",
    "import bs4 as bs \n",
    "\n",
    "from time import sleep\n",
    "from time import time\n",
    "from random import randint\n",
    "\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redeclaring the lists to store data in \n",
    "\n",
    "titles = []\n",
    "urls = []\n",
    "dates = []\n",
    "\n",
    "years = [str(i) for i in range(2008,2019)] \n",
    "\n",
    "headers = {\"Accept-Language\": \"en-US, en;q=0.5\"}\n",
    "\n",
    "# For every year in the interval\n",
    "for year in years:\n",
    "    \n",
    "    # Make a get request\n",
    "    source = requests.get('http://www.cityu.edu.hk/com/News_News.aspx?year=' + year, headers = headers)\n",
    "\n",
    "    # Pause the loop\n",
    "    sleep(randint(1,3))\n",
    "\n",
    "    # Parse the content of the request with BeautifulSoup\n",
    "    page_html = bs.BeautifulSoup(source.content, 'html.parser')\n",
    "\n",
    "    # Select all the 'containers' (a table row) from a single page (one year)\n",
    "    news_containers = page_html.find_all('table', class_ = 'cityu-width-full') \n",
    "    \n",
    "    # For every piece of news \n",
    "    for container in news_containers:\n",
    "\n",
    "        try: \n",
    "            for title in container.find_all('a'): \n",
    "                titles.append(title.text.strip())\n",
    "        except: \n",
    "            title = \"no_title\"\n",
    "            titles.append(title)\n",
    "            \n",
    "        try:\n",
    "            for url in container.find_all('a'): \n",
    "                urls.append(url.get('href')) \n",
    "        except:\n",
    "            url = \"no_url\"\n",
    "            urls.append(url)\n",
    "\n",
    "        try:\n",
    "            for row in container.find_all('tr'): \n",
    "                date = row.select('div:nth-of-type(2)')\n",
    "                dates.append(date)\n",
    "        except: \n",
    "            date = \"no_date\"\n",
    "            dates.append(date)\n",
    "\n",
    "print(len(titles))\n",
    "print(len(urls))\n",
    "print(len(dates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a dict first\n",
    "\n",
    "data_10y = {\n",
    "    'titles': titles,\n",
    "    'urls': urls,\n",
    "    'dates': dates\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a Pandas frame from a dict \n",
    "# guideline: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.from_dict.html\n",
    "\n",
    "pd_CityUnews_10y = pd.DataFrame.from_dict(data_10y, orient ='index').transpose()\n",
    "\n",
    "print(pd_CityUnews_10y.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_CityUnews_10y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd_CityUnews_10y.to_csv('pd_CityUnews_10y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## challenges\n",
    "\n",
    "1. compile a programme to \"visit\" and scrape all the news urls, and store the news articles in one column; \n",
    "2. using the similar codes to harvest this [professional lectures](http://www.cityu.edu.hk/com/News_Lectures.aspx?YearSemester=2009_A) page, store all the data in a pd date frame (for the videos, please indicate the url to the video). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
